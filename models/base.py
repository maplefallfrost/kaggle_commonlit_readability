import torch
import torch.nn as nn

from loss import LossWrapper
from util import get_class_to_score, prob_to_mean

class BaseModel(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__()
    
    def predict(self, collate_batch, dataset_property, **kwargs):
        """
        Input
        collate_batch: dict. generated by correspoding Collator.
            assume key '{dataset_name}_token_ids' exists.
        Ouptut
        output: torch.Tensor. size [batch_size]
        """
        output_dict, _ = self.forward(collate_batch, dataset_property=dataset_property)
        if dataset_property.get('predict_method', None) == 'knn':
            if 'knn_helper' not in kwargs:
                raise ValueError("predict method: knn require 'knn_helper' parameter in kwargs")
            knn_helper = kwargs['knn_helper']
            pred_emb = output_dict["_".join([dataset_property['name'], 'last_emb'])].cpu().numpy()
            pred = knn_helper.predict(pred_emb)
            return pred

        task = dataset_property["task"]
        label_name = "_".join([dataset_property['name'], dataset_property['branches'][0]])
        output = output_dict[label_name]
        if task == 'reg':
            return output.view(-1).cpu().numpy()
        elif task == 'cls':
            class_to_score = get_class_to_score(
                dataset_property['range_min'],
                dataset_property['range_max'],
                dataset_property['interval']
            ).to(self.dummy_param.device)
            mean = prob_to_mean(output, class_to_score)
            return mean
        else:
            raise ValueError(f"Unknown task {task}. Should be in (cls/reg)")
