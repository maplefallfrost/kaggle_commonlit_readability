key:
  k_fold: 5
  rng_seed: 0
  model_type: "roberta"
  model_name: "roberta-base"
  embedding_method: "weight-pool"
  checkpoint_dir: "./checkpoints/roberta_base_cls_hard_label"
  pretrained_dir: "./checkpoints/pretrained/roberta_base"

  train_method: "vanilla"
  scheduler_method: 'cosine'
  batch_size: 16
  max_epoch: 10
  weight_decay: 0.01
  optimizer_name: "AdamW"
  lr: 5e-5
  embedding_layer_start: 9
  warmup_proportion: 0.1
  gradient_accumulation_steps: 1
  hidden_dropout_prob: 0.0
  attention_probs_dropout_prob: 0.0

  dataset_properties:
    -
      name: commonlit
      dataset_class_name: commonlit_soft_label
      task: "cls"
      train_data_path: "../data/train_with_soft_label.csv"
      text_column: 'text'
      loss_name: 'NLL'
      evaluator: 'RMSE'
      log_every: 10
      eval_every: 10
      branches:
        - soft_label
      num_classes:
        - 67
      last_layers:
        - linear_softmax

      range_min: -4.299888984
      range_max: 2.358289505 
      interval: 0.1
