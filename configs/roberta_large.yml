key:
  k_fold: 5
  rng_seed: 0
  model_name: "roberta-large"
  embedding_method: "weight-pool"
  checkpoint_dir: "./checkpoints/roberta_large_dist_loss"
  pretrained_dir: "./checkpoints/pretrained/roberta_large"

  train_method: "vanilla"
  scheduler_method: 'cosine'
  
  batch_size: 8
  max_epoch: 10
  weight_decay: 0.01
  optimizer_name: "AdamW"
  lr: 5e-5
  warmup_steps: 0
  embedding_layer_start: 21
  gradient_accumulation_steps: 2

  dataset_properties:
    -
      name: commonlit
      task: "reg"
      train_data_path: "../data/train.csv"
      text_column: 'text'
      loss_name: 'dist'
      evaluator: 'RMSE'
      log_every: 10
      eval_every: 10
      branches:
        - label
        - standard_error
      num_classes:
        - 1
        - 1
